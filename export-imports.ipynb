{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTS-EXPORTS FROM THE EU: TIME SERIES, VISUALITAZION AND CLUSTERING\n",
    "\n",
    "In this exercise I am going to use diverse methods in order to understand the trading behaviours of the countries beside the EU (conformed by the 28 states) resulting for that a different categories in order of importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practical objective of the exercise:\n",
    "    - Better comprehension of forloops and if clauses\n",
    "    - Easy aplication of machine learning (clustering Kmeans)\n",
    "    - Matplot views\n",
    "    - Reporting: Tableau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we import the necesary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.path # our path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing our data\n",
    "\n",
    "Source: Eurostat\n",
    "\n",
    "The format of our file is excel. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"eu28_allyears.xlsx\",skiprows=4,skipfooter=7)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning and ordering data\n",
    "\n",
    " 1) Cleaning unnecesary columns\n",
    " \n",
    " 2) Renaming the columns for better understanding\n",
    " \n",
    " 3) Dropping unnecesary information and reindexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecesary columns\n",
    "\n",
    "name_cols = []\n",
    "\n",
    "for i in df.columns:\n",
    "    if i.startswith(\"Import Supl Unit\") or i.startswith(\"Export Supl Unit\"):\n",
    "        pass\n",
    "    else:\n",
    "        name_cols.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[name_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming\n",
    "\n",
    "name_cols = []\n",
    "\n",
    "for position, i in enumerate(df.columns):\n",
    "    \n",
    "    if position==0:\n",
    "        name_cols.append(i)\n",
    "    elif i.startswith(\"Import Value to\"):\n",
    "        word = \"import\" + \"_\" + df.iloc[1,position]\n",
    "        name_cols.append(word)\n",
    "    elif i.startswith(\"Import Qty to the\"):\n",
    "        word = \"import_Qty\" + \"_\" + df.iloc[1,position]\n",
    "        name_cols.append(word)         \n",
    "    elif i.startswith(\"Export Value from\"):\n",
    "        word = \"export\" + \"_\" + df.iloc[1,position]\n",
    "        name_cols.append(word)      \n",
    "    elif i.startswith(\"Export Qty from the\"):\n",
    "        word = \"export_Qty\" + \"_\" + df.iloc[1,position]\n",
    "        name_cols.append(word)    \n",
    "    else:\n",
    "        pass\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dict_name = dict(zip(df.columns,name_cols))\n",
    "dict_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns=dict_name,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dropping information adn reset\n",
    "df = df.drop([0,1,2],axis=0)\n",
    "df.reset_index(drop=True,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index(keys=\"Indicators\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info() # to understand our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "\n",
    "I put it under # symbol to not be ejecuted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization of imports to EU\n",
    "#for country in df.index:\n",
    "   # plt.figure(figsize=(20,5))\n",
    "   #  plt.plot(df.columns[0:16].values,df.loc[country][0:16].values)\n",
    "   # plt.xlabel(df.loc[country][0:1].values)\n",
    "   # plt.ylabel(\"euros\")\n",
    "   # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization of exports from EU\n",
    "#for country in df.index:\n",
    "   # plt.figure(figsize=(20,5))\n",
    "   # plt.plot(df.columns[32:48].values,df.loc[country][32:48].values)\n",
    "   # plt.xlabel(df.loc[country][0:1].values)\n",
    "   # plt.ylabel(\"euros\")\n",
    "   # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLUSTERING EXPORTS-IMPORTS\n",
    "\n",
    "In this section I am going to import and use the Kmeans algorithm from the sklearn library that will separate for us the diverse countries in 3 groups, attending to the euclidian distance of his position (settled by the exports and the imports in the last year of the dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[[\"import_2018\",\"export_2018\"]]\n",
    "X.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import k_means\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Normalizing data.\n",
    "\n",
    "As with any Machine Learning algorithm that uses distance functions, the data must be normalized before applying the algorithm. In this case we will use the MinMaxScaler () function that normalizes all data between [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "min_max_scaler = MinMaxScaler() \n",
    "X_normalize = min_max_scaler.fit_transform(X)\n",
    "X_normalize = pd.DataFrame(X_normalize) # Hay que convertir a DF el resultado.\n",
    "X_normalize.rename(columns={0:\"import_18\",1:\"export_18\"},inplace=True)\n",
    "X_normalize.set_index(X.index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_normalize.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphic representation in order to see posible errors\n",
    "\n",
    "x = X_normalize['import_18'].values\n",
    "y = X_normalize['export_18'].values\n",
    "plt.xlabel('importaciones')\n",
    "plt.ylabel('exportaciones')\n",
    "plt.title('import-export')\n",
    "plt.plot(x,y,'o',markersize=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "cluster = k_means(X,k)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "centroids = cluster[0]\n",
    "centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we incorporate the \"importance\" column to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['importance'] = cluster[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cluster[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Graphic representation with the clusters by color\n",
    "plt.figure()\n",
    "plt.scatter(X_normalize['import_18'].values,X_normalize['export_18'].values,c = df['importance'])\n",
    "plt.xlabel('imports')\n",
    "plt.ylabel(\"exports\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df['importance'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to reasing the posible exit of the cluster number assignament to the data criteria. We will always have many similar countries and not much of them that stand out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "value_count = df['importance'].value_counts().sort_values(ascending=False)\n",
    "#print(value_count)\n",
    "#value_count.sort_values(ascending=False)\n",
    "value_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_dict = {}\n",
    "for i in range(len(value_count.index)):\n",
    "    if i==0:\n",
    "        name_dict[value_count.index[i]] = \"low\"\n",
    "    elif i==1:\n",
    "        name_dict[value_count.index[i]] = \"high\"\n",
    "    else:\n",
    "        name_dict[value_count.index[i]] = \"very_high\"\n",
    "        \n",
    "name_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"importance\"].replace(name_dict,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[\"importance\"] #exit of the importance of the countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_relevant = df [ df['importance'].isin(['very_high','high'])]\n",
    "df_relevant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time series of the most relevant countries by the exports from the EU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for country in df_relevant.index:\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.plot(df_relevant.columns[32:48].values,df_relevant.loc[country][32:48].values)\n",
    "    plt.xlabel(df_relevant.loc[country][0:1].values)\n",
    "    plt.xlabel(country)\n",
    "    plt.ylabel(\"euros\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_relevant.sort_values(['import_2018'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install dash==1.6.0  # The core dash backend\n",
    "# pip install dash-daq==0.2.1  # DAQ components (newly open-sourced!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dash_core_components\n",
    "#print(dash_core_components.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En desarrollo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Already executed for Tableau\n",
    "# import_exports = df.to_excel('import_exports.xls',sheet_name='df')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TABLEAU\n",
    "\n",
    "The reporting of this work will be in Tableau. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
